import streamlit as st
import requests, base64, re, pandas as pd, json
from urllib.parse import quote
from datetime import datetime, timedelta, date, timezone, time as dtime

# =========================
# ê¸°ë³¸ UI ì„¤ì •
# =========================
st.set_page_config(page_title="ì—°êµ¬ì‹¤ ì‹œì•½ OCR / ì¬ê³  ê´€ë¦¬", page_icon="ğŸ§ª", layout="wide")
st.markdown("""
<style>
.stButton>button {background:#16a34a;color:white;border:none;border-radius:10px;padding:0.6rem 1rem;font-weight:600;}
.stButton>button:hover {background:#15803d;}
.block-container {padding-top:1.1rem; padding-bottom:2rem;}
</style>
""", unsafe_allow_html=True)
st.title("ğŸ§ª ì—°êµ¬ì‹¤ ì‹œì•½ OCR / ì¬ê³  ê´€ë¦¬")

# =========================
# Secrets (Streamlit â†’ Secrets)
# =========================
AIRTABLE_TOKEN        = st.secrets.get("AIRTABLE_TOKEN", "")
AIRTABLE_BASE_ID      = st.secrets.get("AIRTABLE_BASE_ID", "")

# ê¸°ë¡ í…Œì´ë¸”(íŠ¸ëœì­ì…˜)
AIRTABLE_TABLE_ID     = st.secrets.get("AIRTABLE_TABLE_ID", "")                 # tbl... í˜•íƒœ ê¶Œì¥
AIRTABLE_TABLE_NAME   = st.secrets.get("AIRTABLE_TABLE_NAME", "Lab OCR Results")

# ë§ˆìŠ¤í„° í…Œì´ë¸”(Materials)
MATERIALS_TABLE_ID    = st.secrets.get("MATERIALS_TABLE_ID", "")
MATERIALS_TABLE_NAME  = st.secrets.get("MATERIALS_TABLE_NAME", "Materials")

# íœ´ì§€í†µ í…Œì´ë¸”(ì„ íƒ) â€” ì—†ìœ¼ë©´ ì†Œí”„íŠ¸ì‚­ì œ
TRASH_TABLE_ID        = st.secrets.get("TRASH_TABLE_ID", "")
TRASH_TABLE_NAME      = st.secrets.get("TRASH_TABLE_NAME", "Lab OCR Trash")

IMGBB_KEY             = st.secrets.get("IMGBB_KEY", "")
DEFAULT_GCP_KEY       = st.secrets.get("GCP_KEY", "")

# =========================
# í˜¸í™˜ìš© datetime ì…ë ¥ í—¬í¼ (Streamlit êµ¬ë²„ì „ ëŒ€ì‘)
# =========================
def datetime_input_compat(label: str, default_dt: datetime) -> datetime:
    d = st.date_input(f"{label} (ë‚ ì§œ)", value=default_dt.date())
    t_default = default_dt.time().replace(microsecond=0)
    t = st.time_input(f"{label} (ì‹œê°„)", value=t_default)
    if isinstance(t, dtime):
        combined = datetime.combine(d, t)
        try:
            return combined.replace(tzinfo=default_dt.tzinfo)
        except Exception:
            return combined
    return default_dt

# =========================
# ìœ í‹¸
# =========================
def show_df(df: pd.DataFrame):
    df2 = df.copy()
    df2.index = range(1, len(df2) + 1)  # 1ë¶€í„° ì‹œì‘
    df2.index.name = "No."
    st.dataframe(df2, use_container_width=True)

CAS_RE = re.compile(r"\b\d{2,7}-\d{2}-\d\b")
def extract_cas(text: str) -> str:
    m = CAS_RE.search(text or "")
    return m.group(0) if m else ""

def table_ref(table_id, table_name):
    return table_id or quote(table_name, safe="")

def at_headers():
    return {"Authorization": f"Bearer {AIRTABLE_TOKEN}", "Content-Type": "application/json"}

def at_get_all(base_id, table_id_or_name):
    """Airtable ì „ ë ˆì½”ë“œ ì¡°íšŒ (í˜ì´ì§€ë„¤ì´ì…˜ ì²˜ë¦¬)"""
    out = []
    url = f"https://api.airtable.com/v0/{base_id}/{table_id_or_name}"
    params = {"pageSize": 100}
    while True:
        r = requests.get(url, headers=at_headers(), params=params, timeout=30)
        r.raise_for_status()
        data = r.json()
        out.extend(data.get("records", []))
        off = data.get("offset")
        if not off:
            break
        params["offset"] = off
    return out

def at_find_one(base_id, table_id_or_name, formula: str):
    """filterByFormulaë¡œ ë‹¨ê±´ ì¡°íšŒ"""
    url = f"https://api.airtable.com/v0/{base_id}/{table_id_or_name}"
    r = requests.get(url, headers=at_headers(),
                     params={"maxRecords": 1, "filterByFormula": formula},
                     timeout=20)
    r.raise_for_status()
    js = r.json()
    return js.get("records", [None])[0]

def at_get_record(base_id, table_id_or_name, record_id: str):
    url = f"https://api.airtable.com/v0/{base_id}/{table_id_or_name}/{record_id}"
    r = requests.get(url, headers=at_headers(), timeout=20)
    if r.status_code == 200:
        return r.json()
    return None

def at_update_record(base_id, table_id_or_name, record_id: str, fields: dict):
    url = f"https://api.airtable.com/v0/{base_id}/{table_id_or_name}/{record_id}"
    r = requests.patch(url, json={"fields": fields}, headers=at_headers(), timeout=20)
    return r

def at_delete_record(base_id, table_id_or_name, record_id: str):
    url = f"https://api.airtable.com/v0/{base_id}/{table_id_or_name}/{record_id}"
    r = requests.delete(url, headers=at_headers(), timeout=20)
    return r

def ensure_material_record(cas_no: str, name_guess: str = ""):
    """Materialsì— CAS ì—†ìœ¼ë©´ ìë™ ìƒì„±"""
    if not cas_no:
        return None
    mref = table_ref(MATERIALS_TABLE_ID, MATERIALS_TABLE_NAME)
    try:
        rec = at_find_one(AIRTABLE_BASE_ID, mref, formula=f"{{CAS}} = '{cas_no}'")
        if rec:
            return rec  # ì´ë¯¸ ìˆìŒ
        payload = {"fields": {"CAS": cas_no}}
        if name_guess:
            payload["fields"]["name"] = name_guess[:100]
        url = f"https://api.airtable.com/v0/{AIRTABLE_BASE_ID}/{mref}"
        r = requests.post(url, json=payload, headers=at_headers(), timeout=20)
        if r.status_code in (200, 201):
            return r.json()
    except:
        pass
    return None

def set_material_name_if_missing(cas_no: str, mats_idx: dict, name_hint: str = ""):
    """Materialsì— nameì´ ì—†ìœ¼ë©´ PubChem ì¡°íšŒí•´ ì±„ì›€(ê°€ëŠ¥í•˜ë©´)"""
    if not cas_no:
        return
    mref = table_ref(MATERIALS_TABLE_ID, MATERIALS_TABLE_NAME)
    current = mats_idx.get(cas_no, {})
    if current.get("name"):
        return
    name_found = None
    try:
        url = f"https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/name/{cas_no}/property/Title,IUPACName/JSON"
        r = requests.get(url, timeout=12)
        if r.status_code == 200:
            js = r.json()
            props = js.get("PropertyTable", {}).get("Properties", [])
            if props:
                p = props[0]
                name_found = p.get("Title") or p.get("IUPACName")
    except:
        pass
    if not name_found:
        name_found = (name_hint or "").strip()
        if "\n" in name_found:
            name_found = name_found.split("\n", 1)[0]
        name_found = name_found[:100]
    if not name_found:
        return
    try:
        rec = at_find_one(AIRTABLE_BASE_ID, mref, formula=f"{{CAS}} = '{cas_no}'")
        if rec:
            rid = rec["id"]
            at_update_record(AIRTABLE_BASE_ID, mref, rid, {"name": name_found})
        else:
            requests.post(
                f"https://api.airtable.com/v0/{AIRTABLE_BASE_ID}/{mref}",
                json={"fields": {"CAS": cas_no, "name": name_found}},
                headers=at_headers(), timeout=20
            )
    except:
        pass

def run_ocr(image_bytes: bytes, gcp_key: str) -> dict:
    url = f"https://vision.googleapis.com/v1/images:annotate?key={gcp_key}"
    payload = {"requests": [{
        "image": {"content": base64.b64encode(image_bytes).decode("utf-8")},
        "features": [{"type": "TEXT_DETECTION"}]
    }]}
    return requests.post(url, json=payload, timeout=40).json()

def upload_to_imgbb(image_bytes, filename: str) -> str | None:
    if not IMGBB_KEY:
        return None
    try:
        b64 = base64.b64encode(image_bytes).decode("utf-8")
        r = requests.post("https://api.imgbb.com/1/upload",
                          data={"key": IMGBB_KEY, "image": b64, "name": filename},
                          timeout=25)
        r.raise_for_status()
        return r.json()["data"]["url"]
    except:
        return None

def save_to_airtable(fields: dict):
    if not (AIRTABLE_TOKEN and AIRTABLE_BASE_ID):
        return False, "Airtable secrets ë¯¸ì„¤ì •"
    tref = table_ref(AIRTABLE_TABLE_ID, AIRTABLE_TABLE_NAME)
    url = f"https://api.airtable.com/v0/{AIRTABLE_BASE_ID}/{tref}"
    r = requests.post(url, json={"fields": fields}, headers=at_headers(), timeout=30)
    ok = r.status_code in (200, 201)
    return ok, (r.text if not ok else "OK")

# ===== íœ´ì§€í†µ(Undo) ê´€ë ¨ =====
def trash_enabled() -> bool:
    return bool(TRASH_TABLE_ID or TRASH_TABLE_NAME)

def trash_ref() -> str:
    return table_ref(TRASH_TABLE_ID, TRASH_TABLE_NAME)

def save_to_trash(orig_record: dict) -> bool:
    """
    íœ´ì§€í†µ í…Œì´ë¸”ì— ì›ë³¸ì„ JSONìœ¼ë¡œ ì €ì¥.
    íœ´ì§€í†µ í…Œì´ë¸” í•„ìˆ˜ í•„ë“œ:
      - original_record_id (single line)
      - deleted_at (date/time)
      - raw (long text)
    """
    if not trash_enabled() or not orig_record:
        return False
    try:
        tref = trash_ref()
        fields = {
            "original_record_id": orig_record.get("id", ""),
            "deleted_at": datetime.now(timezone.utc).replace(microsecond=0).isoformat().replace("+00:00","Z"),
            "raw": json.dumps(orig_record, ensure_ascii=False)
        }
        r = requests.post(
            f"https://api.airtable.com/v0/{AIRTABLE_BASE_ID}/{tref}",
            json={"fields": fields}, headers=at_headers(), timeout=20
        )
        return r.status_code in (200, 201)
    except:
        return False

# ì œ4ë¥˜ ì§€ì •ìˆ˜ëŸ‰(ê³ ì •ê°’)
LEGAL_LIMITS_L = {
    "íŠ¹ìˆ˜ì¸í™”ë¬¼": 100.0,
    "ì œ1ì„ìœ ë¥˜(ë¹„ìˆ˜ìš©ì„±)": 600.0,
    "ì œ1ì„ìœ ë¥˜(ìˆ˜ìš©ì„±)": 1700.0,
    "ì•Œì½”ì˜¬ë¥˜": 4100.0,
}

# ë‚´ì¥ ê°„ì´ ë°€ë„ (g/mL) & ìœ ë³„ ë§¤í•‘ (ì—†ìœ¼ë©´ Materials ê°’ì„ ì‚¬ìš©)
BUILTIN_CHEM = {
    # CAS        name_hint,         hazard_class,         density_g_per_ml
    "64-17-5":   ("Ethanol",        "ì•Œì½”ì˜¬ë¥˜",           0.789),
    "67-63-0":   ("Isopropanol",    "ì•Œì½”ì˜¬ë¥˜",           0.786),
    "67-56-1":   ("Methanol",       "ì•Œì½”ì˜¬ë¥˜",           0.792),
    "67-64-1":   ("Acetone",        "ì œ1ì„ìœ ë¥˜(ìˆ˜ìš©ì„±)",  0.791),
    "75-05-8":   ("Acetonitrile",   "ì œ1ì„ìœ ë¥˜(ìˆ˜ìš©ì„±)",  0.786),
    "108-88-3":  ("Toluene",        "ì œ1ì„ìœ ë¥˜(ë¹„ìˆ˜ìš©ì„±)",0.867),
    "110-54-3":  ("n-Hexane",       "ì œ1ì„ìœ ë¥˜(ë¹„ìˆ˜ìš©ì„±)",0.655),
    "60-29-7":   ("Diethyl ether",  "íŠ¹ìˆ˜ì¸í™”ë¬¼",         0.713),
}

def load_materials_index():
    """Materialsë¥¼ CAS í‚¤ë¡œ ë¬¶ì–´ name, designated_qty, unit, hazard_class, density ì œê³µ"""
    mref = table_ref(MATERIALS_TABLE_ID, MATERIALS_TABLE_NAME)
    try:
        mats = at_get_all(AIRTABLE_BASE_ID, mref)
    except Exception as e:
        st.warning(f"Materials ë¡œë“œ ì‹¤íŒ¨: {e}")
        mats = []
    out = {}
    for r in mats:
        f = r.get("fields",{})
        cas = (f.get("CAS") or "").strip()
        if not cas:
            continue
        out[cas] = {
            "name": f.get("name",""),
            "designated_qty": f.get("designated_qty"),
            "unit": (f.get("Unit") or f.get("unit") or ""),
            "hazard_class": f.get("hazard_class",""),
            "density_g_per_ml": f.get("density_g_per_ml"),
        }
    return out

def classify_hazard(cas: str, mats_idx: dict) -> str | None:
    if cas in mats_idx and mats_idx[cas].get("hazard_class"):
        return mats_idx[cas]["hazard_class"]
    if cas in BUILTIN_CHEM and BUILTIN_CHEM[cas][1]:
        return BUILTIN_CHEM[cas][1]
    return None

def get_density(cas: str, mats_idx: dict) -> float | None:
    if cas in mats_idx and mats_idx[cas].get("density_g_per_ml"):
        try:
            return float(mats_idx[cas]["density_g_per_ml"])
        except:
            pass
    if cas in BUILTIN_CHEM and BUILTIN_CHEM[cas][2]:
        return BUILTIN_CHEM[cas][2]
    return None

def to_liters(amount, unit: str, density_g_per_ml: float | None) -> float | None:
    if amount is None or unit is None:
        return None
    unit = unit.strip()
    try:
        val = float(amount)
    except:
        return None

    if unit == "L":
        return val
    if unit == "mL":
        return val / 1000.0
    if unit == "g":
        if density_g_per_ml and density_g_per_ml > 0:
            return (val / density_g_per_ml) / 1000.0
        return None
    if unit == "kg":
        if density_g_per_ml and density_g_per_ml > 0:
            g = val * 1000.0
            return (g / density_g_per_ml) / 1000.0
        return None
    return None  # EA, cyl ë“±ì€ í™˜ì‚° ë¶ˆê°€

def fmt_int(x) -> str:
    try:
        return f"{int(round(float(x)))}"
    except:
        return ""

def fmt_pct(ratio) -> str:
    if ratio is None:
        return ""
    try:
        return f"{int(round(float(ratio)*100))}%"
    except:
        return ""

# =========================
# íƒ­
# =========================
tab1, tab2, tab3, tab4, tab5 = st.tabs([
    "ğŸ“· ê¸°ë¡ (OCR/ì €ì¥)",
    "ğŸ“¦ ì¬ê³  í˜„í™©",
    "ğŸ­ ìœ„í—˜ë¬¼(ì œ4ë¥˜) í˜„í™©",
    "ğŸ”„ ì…ì¶œê³  ë¡œê·¸",
    "ğŸ—ƒï¸ íœ´ì§€í†µ(ë³µì›)"
])

# =========================
# TAB1: ê¸°ë¡ (OCR/ì €ì¥)
# =========================
with tab1:
    if "last" not in st.session_state:
        st.session_state.last = {"dept":"","lab":"","bld":"","room":"","io":"ì…ê³ ","unit":"g"}

    uploaded_file = st.file_uploader("ë¼ë²¨ ì •ë©´ ì‚¬ì§„ ì—…ë¡œë“œ", type=["jpg","jpeg","png"])
    gcp_key = st.text_input("ğŸ”‘ Google Vision API Key (Secretsì— ìˆìœ¼ë©´ ë¹„ì›Œë„ ë¨)",
                            value=DEFAULT_GCP_KEY, type="password")

    st.markdown("### ğŸ“‹ ë©”íƒ€ ì •ë³´")
    colA,colB,colC = st.columns(3)
    colD,colE = st.columns(2)

    dept = colA.selectbox("í•™ê³¼",
        ["í™”í•™ê³µí•™ê³¼","ì•ˆì „ê³µí•™ê³¼","ì‹ ì†Œì¬ê³µí•™ê³¼","ê¸°ê³„ì‹œìŠ¤í…œë””ìì¸ê³µí•™ê³¼","ê¸°íƒ€(ì§ì ‘ ì…ë ¥)"],
        index=0)
    lab = colB.text_input("ì‹¤í—˜ì‹¤ëª…", value=st.session_state.last["lab"])
    bld = colC.selectbox("ê±´ë¬¼", ["ì²­ìš´ê´€","ì œ1ê³µí•™ê´€","ì œ2ê³µí•™ê´€","ì–´ìš¸ë¦¼ê´€","ê¸°íƒ€(ì§ì ‘ ì…ë ¥)"], index=0)
    room = colD.text_input("í˜¸ìˆ˜ (ì˜ˆ: 203)", value=st.session_state.last["room"])
    io_type = colE.selectbox("ì…Â·ì¶œê³  êµ¬ë¶„", ["ì…ê³ ","ì¶œê³ ","ë°˜í’ˆ","íê¸°"], index=0)

    if dept.endswith("ì§ì ‘ ì…ë ¥"):
        dept = colA.text_input("í•™ê³¼(ì§ì ‘ ì…ë ¥)", value=st.session_state.last["dept"])
    if bld.endswith("ì§ì ‘ ì…ë ¥"):
        bld = colC.text_input("ê±´ë¬¼(ì§ì ‘ ì…ë ¥)", value=st.session_state.last["bld"])

    st.markdown("### â± ê±°ë˜ ì¼ì‹œ (ìˆ˜ì • ê°€ëŠ¥)")
    now_local = datetime.now().astimezone()
    tx_time_input = datetime_input_compat("ê±°ë˜ì¼ì‹œ", now_local)

    st.markdown("### ğŸ“¦ ìˆ˜ëŸ‰")
    colQ1, colQ2 = st.columns([1,1])
    qty = colQ1.number_input("ìˆ˜ëŸ‰", min_value=0.0, step=1.0, format="%.0f")  # ì •ìˆ˜ ì…ë ¥
    unit = colQ2.selectbox("ë‹¨ìœ„", ["g","mL","L","kg","EA","cyl"],
                           index=["g","mL","L","kg","EA","cyl"].index(st.session_state.last["unit"]))

    st.divider()

    if uploaded_file and gcp_key:
        with st.spinner("ğŸ” OCR ë¶„ì„ ì¤‘â€¦"):
            img_bytes = uploaded_file.getvalue()
            url = f"https://vision.googleapis.com/v1/images:annotate?key={gcp_key}"
            payload = {"requests": [{
                "image": {"content": base64.b64encode(img_bytes).decode("utf-8")},
                "features": [{"type": "TEXT_DETECTION"}]
            }]}
            ocr_json = requests.post(url, json=payload, timeout=40).json()

        text = ""
        try:
            text = ocr_json["responses"][0]["fullTextAnnotation"]["text"]
            st.success("âœ… OCR ì¸ì‹ ì„±ê³µ")
            st.text_area("ì¶”ì¶œ í…ìŠ¤íŠ¸", text, height=220)
        except Exception:
            st.error("âš ï¸ í…ìŠ¤íŠ¸ ì¸ì‹ ì‹¤íŒ¨ (ì›ë³¸ ì‘ë‹µ ì•„ë˜)")
            st.json(ocr_json)

        cas_no = extract_cas(text) if text else ""
        st.code(f"ğŸ” CAS: {cas_no or '(ì—†ìŒ)'}")

        # CAS â†’ ë¬¼ì§ˆëª… ìë™ ì±„ì›€(ê°€ëŠ¥ ì‹œ Materialsì— ë°˜ì˜)
        mats_idx = load_materials_index()
        set_material_name_if_missing(cas_no, mats_idx, name_hint=text)

        ready = bool(text and dept and lab and bld and room and io_type and (qty>=0))
        if not ready:
            st.info("â„¹ OCR/ë©”íƒ€/ìˆ˜ëŸ‰ì„ ì±„ìš°ë©´ ì €ì¥í•  ìˆ˜ ìˆì–´ìš”.")

        if st.button("ğŸ’¾ Airtableì— ì €ì¥", disabled=not ready):
            sign = +1 if io_type=="ì…ê³ " else -1  # ì¶œê³ /ë°˜í’ˆ/íê¸° â†’ ìŒìˆ˜
            img_url = upload_to_imgbb(img_bytes, uploaded_file.name)
            # ISO8601(UTC) ì €ì¥
            tx_dt_utc = tx_time_input.astimezone(timezone.utc).replace(microsecond=0).isoformat().replace("+00:00","Z")

            fields = {
                "Name": uploaded_file.name,
                "ocr_text": text,
                "CAS": cas_no,
                "dept": dept,
                "lab": lab,
                "building": bld,
                "room": room,
                "io_type": io_type,
                "qty": sign * qty,
                "unit": unit,
                "tx_time": tx_dt_utc,   # Airtableì— ë™ì¼ ì´ë¦„ Date/Time í•„ë“œ ê¶Œì¥
                "deleted": False,       # ì†Œí”„íŠ¸ì‚­ì œ í”Œë˜ê·¸(ì—†ìœ¼ë©´ Airtableì— ìƒì„±)
            }
            if img_url:
                fields["Attachments"] = [{"url": img_url, "filename": uploaded_file.name}]

            ok, msg = save_to_airtable(fields)
            if ok:
                ensure_material_record(cas_no, name_guess=text.splitlines()[0] if text else "")
                st.success("âœ… ì €ì¥ ì™„ë£Œ!")
                st.session_state.last = {"dept":dept,"lab":lab,"bld":bld,"room":room,"io":io_type,"unit":unit}
            else:
                if "INVALID_MULTIPLE_CHOICE_OPTIONS" in msg:
                    st.error("âŒ ë“œë¡­ë‹¤ìš´ ì˜µì…˜ì— ì—†ëŠ” ê°’ì…ë‹ˆë‹¤. Airtableì—ì„œ ì˜µì…˜ì„ ì¶”ê°€í•˜ì„¸ìš”.")
                else:
                    st.error(f"âŒ ì €ì¥ ì‹¤íŒ¨: {msg}")
    else:
        st.caption("ì´ë¯¸ì§€ì™€ Vision API Keyë¥¼ ì…ë ¥í•˜ë©´ OCRì„ ì‹œì‘í•©ë‹ˆë‹¤.")

# =========================
# TAB2: ğŸ“¦ ì¬ê³  í˜„í™© â€” CASë³„ / ì‹¤í—˜ì‹¤ë³„
# =========================
with tab2:
    subt1, subt2 = st.tabs(["ğŸ”¬ CASë³„", "ğŸ« ì‹¤í—˜ì‹¤ë³„"])

    # ê³µí†µ ë°ì´í„° ë¡œë”©
    if not (AIRTABLE_TOKEN and AIRTABLE_BASE_ID):
        st.error("Airtable secretsê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    else:
        tx_ref  = table_ref(AIRTABLE_TABLE_ID, AIRTABLE_TABLE_NAME)
        try:
            with st.spinner("ğŸ”„ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘â€¦"):
                tx = at_get_all(AIRTABLE_BASE_ID, tx_ref)
                mats_idx = load_materials_index()
        except Exception as e:
            st.error(f"ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {e}")
            tx, mats_idx = [], {}

        # ì‚­ì œëœ(ì†Œí”„íŠ¸ì‚­ì œ) ì œì™¸
        def not_deleted(rec):
            f = rec.get("fields",{})
            return not bool(f.get("deleted", False))
        tx = [r for r in tx if not_deleted(r)]

    # ---------- CASë³„ ----------
    with subt1:
        st.caption("CASë³„ ì¬ê³ í•©ê³„ë§Œ í‘œì‹œ (ì§€ì •ìˆ˜ëŸ‰/ë¹„ìœ¨ ì œê±°).")
        sums = {}
        for r in tx:
            f = r.get("fields",{})
            cas = (f.get("CAS") or "").strip()
            q   = f.get("qty")
            u   = f.get("unit")
            if not cas or q is None:
                continue
            key = (cas, u or "")
            sums[key] = sums.get(key, 0.0) + float(q)

        rows = []
        for (cas, unit), qty_sum in sums.items():
            m = mats_idx.get(cas, {})
            rows.append({
                "CAS": cas,
                "ë¬¼ì§ˆëª…": m.get("name",""),
                "ì¬ê³ í•©ê³„": f"{int(round(qty_sum))}",
                "ë‹¨ìœ„": unit,
                "ë©”ëª¨": ""
            })

        rows.sort(key=lambda r: int(r["ì¬ê³ í•©ê³„"]) if r["ì¬ê³ í•©ê³„"] else 0, reverse=True)

        if rows:
            df = pd.DataFrame(rows)
            show_df(df)
            st.download_button("ğŸ“¥ CSVë¡œ ë‚´ë ¤ë°›ê¸° (CASë³„)",
                               df.to_csv(index=False).encode("utf-8-sig"),
                               file_name="inventory_by_cas.csv", mime="text/csv")
        else:
            st.caption("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # ---------- ì‹¤í—˜ì‹¤ë³„ ----------
    with subt2:
        st.caption("ì‹¤í—˜ì‹¤ë³„ ì¬ê³ ë¥¼ **L ë‹¨ìœ„ë¡œ í™˜ì‚°**(ê°€ëŠ¥í•œ í•­ëª©)í•˜ì—¬ ìš”ì•½ê³¼ ìƒì„¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤.")
        sum_lab = {}
        detail = []
        skipped = []

        for r in tx:
            f = r.get("fields",{})
            cas = (f.get("CAS") or "").strip()
            q   = f.get("qty")
            unit= f.get("unit")
            bld = f.get("building","")
            room= f.get("room","")
            lab = f.get("lab","")
            if not cas or q is None or not unit:
                continue

            dens = get_density(cas, mats_idx)
            Lval = to_liters(q, unit, dens)
            if Lval is None:
                skipped.append({"CAS": cas, "qty": q, "unit": unit, "building": bld, "room": room, "lab": lab})
                continue

            key = (bld, room, lab)
            sum_lab[key] = sum_lab.get(key, 0.0) + float(Lval)

            m = mats_idx.get(cas, {})
            detail.append({
                "ê±´ë¬¼": bld, "í˜¸ìˆ˜": room, "ì‹¤í—˜ì‹¤": lab,
                "CAS": cas, "ë¬¼ì§ˆëª…": m.get("name",""),
                "í™˜ì‚°ë³´ìœ ëŸ‰(L)": f"{int(round(Lval))}",
                "ì›ìˆ˜ëŸ‰": f"{int(round(float(q)))}", "ì›ë‹¨ìœ„": unit
            })

        rows_sum = [
            {"ê±´ë¬¼": k[0], "í˜¸ìˆ˜": k[1], "ì‹¤í—˜ì‹¤": k[2], "ì´ë³´ìœ ëŸ‰(L)": f"{int(round(v))}"}
            for k,v in sum_lab.items()
        ]
        rows_sum.sort(key=lambda r: int(r["ì´ë³´ìœ ëŸ‰(L)"]) if r["ì´ë³´ìœ ëŸ‰(L)"] else 0, reverse=True)

        st.markdown("#### ğŸ§¾ ì‹¤í—˜ì‹¤ë³„ ìš”ì•½ (L)")
        if rows_sum:
            df_sum = pd.DataFrame(rows_sum)
            show_df(df_sum)
            st.download_button("ğŸ“¥ CSVë¡œ ë‚´ë ¤ë°›ê¸° (ì‹¤í—˜ì‹¤ ìš”ì•½)",
                               df_sum.to_csv(index=False).encode("utf-8-sig"),
                               file_name="inventory_by_lab_summary.csv", mime="text/csv")
        else:
            st.caption("ìš”ì•½í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

        st.markdown("#### ğŸ” ì‹¤í—˜ì‹¤ë³„ ìƒì„¸ (CAS)")
        if detail:
            df_det = pd.DataFrame(detail)
            df_det["__sort__"] = df_det["í™˜ì‚°ë³´ìœ ëŸ‰(L)"].apply(lambda x: int(x) if str(x).isdigit() else 0)
            df_det = df_det.sort_values(by=["ê±´ë¬¼","í˜¸ìˆ˜","ì‹¤í—˜ì‹¤","__sort__"], ascending=[True, True, True, False]).drop(columns="__sort__")
            show_df(df_det)
            st.download_button("ğŸ“¥ CSVë¡œ ë‚´ë ¤ë°›ê¸° (ì‹¤í—˜ì‹¤ ìƒì„¸)",
                               df_det.to_csv(index=False).encode("utf-8-sig"),
                               file_name="inventory_by_lab_detail.csv", mime="text/csv")
        else:
            st.caption("ìƒì„¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

        if skipped:
            with st.expander("âš ï¸ í™˜ì‚° ë¶ˆê°€ í•­ëª© ë³´ê¸° (ë°€ë„/ë‹¨ìœ„ ë¬¸ì œ)"):
                show_df(pd.DataFrame(skipped))

# =========================
# TAB3: ìœ„í—˜ë¬¼(ì œ4ë¥˜) í˜„í™© â€” ìš”ì•½(ìœ ë³„) + ì„¸ë¶€(CASë³„, ìœ„í—˜ë¬¼ë¥˜ëª… í‘œì‹œ)
# =========================
with tab3:
    st.info("ì œ4ë¥˜ ìœ„í—˜ë¬¼ ê¸°ì¤€ìœ¼ë¡œ, ì°½ê³  ì „ì²´ ì €ì¥ëŸ‰(L)ì„ ìœ ë³„ë³„ë¡œ í•©ì‚°í•˜ê³ , CASë³„ ìƒì„¸(ìœ„í—˜ë¬¼ë¥˜ëª… í¬í•¨)ë„ ì œê³µí•©ë‹ˆë‹¤.")

    if not (AIRTABLE_TOKEN and AIRTABLE_BASE_ID):
        st.error("Airtable secretsê°€ í•„ìš”í•©ë‹ˆë‹¤."); st.stop()

    tx_ref = table_ref(AIRTABLE_TABLE_ID, AIRTABLE_TABLE_NAME)

    try:
        with st.spinner("ğŸ”„ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘â€¦"):
            tx = at_get_all(AIRTABLE_BASE_ID, tx_ref)
            mats_idx = load_materials_index()
    except Exception as e:
        st.error(f"ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {e}")
        st.stop()

    # ì‚­ì œ ì œì™¸
    def not_deleted(rec):
        f = rec.get("fields",{})
        return not bool(f.get("deleted", False))
    tx = [r for r in tx if not_deleted(r)]

    subtA, subtB = st.tabs(["ğŸ“¦ ìœ ë³„ ìš”ì•½", "ğŸ” CAS ìƒì„¸"])

    # ----- ìœ ë³„ ìš”ì•½ -----
    with subtA:
        by_class = {}
        skipped  = []
        for r in tx:
            f = r.get("fields",{})
            cas = (f.get("CAS") or "").strip()
            q   = f.get("qty")
            unit= f.get("unit")
            if not cas or q is None or not unit:
                continue
            dens = get_density(cas, mats_idx)
            Lval = to_liters(q, unit, dens)
            if Lval is None:
                skipped.append({"CAS": cas, "qty": q, "unit": unit})
                continue
            hclass = classify_hazard(cas, mats_idx)
            if not hclass:
                hclass = "ë¯¸ë¶„ë¥˜"
            by_class[hclass] = by_class.get(hclass, 0.0) + Lval

        disp_rows2, csv_rows2 = [], []
        order = ["íŠ¹ìˆ˜ì¸í™”ë¬¼", "ì œ1ì„ìœ ë¥˜(ë¹„ìˆ˜ìš©ì„±)", "ì œ1ì„ìœ ë¥˜(ìˆ˜ìš©ì„±)", "ì•Œì½”ì˜¬ë¥˜", "ë¯¸ë¶„ë¥˜"]
        for key in order:
            cur = by_class.get(key, 0.0)
            limit = LEGAL_LIMITS_L.get(key, 0.0)
            ratio = (cur / limit) if (limit and limit>0) else None
            remain = max(limit - cur, 0.0) if limit else 0.0
            status = ("ì´ˆê³¼" if ratio is not None and ratio>=1.0 else
                      "ê²½ê³ " if ratio is not None and ratio>=0.5 else
                      "ì£¼ì˜" if ratio is not None and ratio>=0.2 else "ì •ìƒ")

            row = {
                "êµ¬ë¶„": key,
                "í˜„ì¬ë³´ìœ ëŸ‰(L)": fmt_int(cur),
                "ì§€ì •ìˆ˜ëŸ‰(L)": fmt_int(limit),
                "ì”ì—¬í—ˆìš©ëŸ‰(L)": fmt_int(remain),
                "ë¹„ìœ¨": fmt_pct(ratio) if ratio is not None else "",
                "ìƒíƒœ": status
            }
            disp_rows2.append(row); csv_rows2.append(row.copy())

        st.markdown("#### ğŸ“¦ ì œ4ë¥˜ ìœ„í—˜ë¬¼ ì €ì¥ëŸ‰ í˜„í™© (ìœ ë³„ í•©ê³„)")
        if not disp_rows2:
            st.caption("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            df2 = pd.DataFrame(disp_rows2)
            show_df(df2)
            st.download_button("ğŸ“¥ CSVë¡œ ë‚´ë ¤ë°›ê¸° (ì œ4ë¥˜ ìœ ë³„ ìš”ì•½)",
                               pd.DataFrame(csv_rows2).to_csv(index=False).encode("utf-8-sig"),
                               file_name="hazard_class_4_summary.csv", mime="text/csv")

        if skipped:
            with st.expander("âš ï¸ í™˜ì‚° ë¶ˆê°€ í•­ëª© ë³´ê¸°"):
                show_df(pd.DataFrame(skipped))

    # ----- CAS ìƒì„¸(ìœ„í—˜ë¬¼ë¥˜ëª… í‘œì‹œ) -----
    with subtB:
        sums = {}
        detail_rows = []
        for r in tx:
            f = r.get("fields",{})
            cas = (f.get("CAS") or "").strip()
            q   = f.get("qty")
            unit= f.get("unit")
            if not cas or q is None or not unit:
                continue
            dens = get_density(cas, mats_idx)
            Lval = to_liters(q, unit, dens)
            if Lval is None:
                continue
            key = (cas,)
            sums[key] = sums.get(key, 0.0) + float(Lval)

        for (cas,) , Lsum in sums.items():
            m = mats_idx.get(cas, {})
            hclass = classify_hazard(cas, mats_idx) or "ë¯¸ë¶„ë¥˜"
            limit = LEGAL_LIMITS_L.get(hclass, 0.0)
            remain = max(limit - Lsum, 0.0) if limit else 0.0
            detail_rows.append({
                "CAS": cas,
                "ë¬¼ì§ˆëª…": m.get("name",""),
                "ìœ„í—˜ë¬¼ë¥˜ëª…": hclass,
                "ì¬ê³ í•©ê³„(L)": fmt_int(Lsum),
                "ì§€ì •ìˆ˜ëŸ‰(L)": fmt_int(limit),
                "ì”ì—¬í—ˆìš©ëŸ‰(L)": fmt_int(remain),
            })

        detail_rows.sort(key=lambda r: int(r["ì¬ê³ í•©ê³„(L)"]) if r["ì¬ê³ í•©ê³„(L)"] else 0, reverse=True)

        st.markdown("#### ğŸ” CASë³„ ìƒì„¸ (ìœ„í—˜ë¬¼ë¥˜ëª… í¬í•¨)")
        if detail_rows:
            dfh = pd.DataFrame(detail_rows)
            show_df(dfh)
            st.download_button("ğŸ“¥ CSVë¡œ ë‚´ë ¤ë°›ê¸° (ì œ4ë¥˜ CAS ìƒì„¸)",
                               dfh.to_csv(index=False).encode("utf-8-sig"),
                               file_name="hazard_cas_detail.csv", mime="text/csv")
        else:
            st.caption("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

# =========================
# TAB4: ğŸ”„ ì…ì¶œê³  ë¡œê·¸ â€” í‘œ ì•ˆì—ì„œ ë°”ë¡œ ì‚­ì œ/ì¼ì‹œìˆ˜ì • (Undo ì§€ì›)
# =========================
with tab4:
    st.info("í‘œ ì•ˆì—ì„œ 'ì‚­ì œ' ì²´í¬í•˜ê±°ë‚˜ 'ìƒˆ ì¼ì‹œ'ë¥¼ ìˆ˜ì •í•œ ë’¤, ì•„ë˜ 'ì„ íƒ í•­ëª© ì ìš©' ë²„íŠ¼ì„ ëˆ„ë¥´ì„¸ìš”. (Airtableì— tx_time í•„ë“œê°€ ìˆì–´ì•¼ í•©ë‹ˆë‹¤)")

    if not (AIRTABLE_TOKEN and AIRTABLE_BASE_ID):
        st.error("Airtable secretsê°€ í•„ìš”í•©ë‹ˆë‹¤."); st.stop()

    tx_ref  = table_ref(AIRTABLE_TABLE_ID, AIRTABLE_TABLE_NAME)

    # ê¸°ë³¸ ê¸°ê°„: ìµœê·¼ 30ì¼
    today = date.today()
    default_start = today - timedelta(days=30)
    colf1, colf2 = st.columns(2)
    start_d = colf1.date_input("ì‹œì‘ì¼", value=default_start)
    end_d   = colf2.date_input("ì¢…ë£Œì¼", value=today)

    # ì›ë³¸ ë°ì´í„° ë¡œë“œ
    try:
        with st.spinner("ğŸ”„ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘â€¦"):
            tx = at_get_all(AIRTABLE_BASE_ID, tx_ref)
            mats_idx = load_materials_index()
    except Exception as e:
        st.error(f"ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {e}")
        tx, mats_idx = [], {}

    # ì†Œí”„íŠ¸ì‚­ì œ ì œì™¸
    def not_deleted(rec):
        f = rec.get("fields",{})
        return not bool(f.get("deleted", False))
    tx = [r for r in tx if not_deleted(r)]

    # í‘œì‹œ/í¸ì§‘ìš© ë°ì´í„° êµ¬ì„±
    def pick_time(fields, created_iso):
        t = fields.get("tx_time")
        return t if t else (created_iso or "")

    def in_range_iso(iso_str: str) -> bool:
        if not iso_str:
            return True
        try:
            dt = datetime.fromisoformat(iso_str.replace("Z","+00:00")).date()
            return (start_d <= dt <= end_d)
        except:
            return True

    rows_for_editor = []
    orig_time_map = {}  # record_id -> iso string (ì›ë˜ ê°’ ë¹„êµìš©)

    for r in tx:
        rid = r.get("id")
        ct  = r.get("createdTime")
        f   = r.get("fields",{})
        iso = pick_time(f, ct)
        if not in_range_iso(iso):
            continue

        cas = (f.get("CAS") or "").strip()
        name = mats_idx.get(cas, {}).get("name","")
        qty = f.get("qty")
        unit= f.get("unit","")
        io  = f.get("io_type","")
        bld = f.get("building","")
        room= f.get("room","")
        lab = f.get("lab","")

        # í¸ì§‘ìš© datetime ê°’ (naiveë¡œ í‘œì‹œ â†’ ì €ì¥ ì‹œ UTCë¡œ ë³€í™˜)
        try:
            base_dt = datetime.fromisoformat(iso.replace("Z","+00:00"))
        except:
            base_dt = datetime.now().astimezone()
        new_dt_default = base_dt.astimezone().replace(microsecond=0).replace(tzinfo=None)

        orig_time_map[rid] = iso
        rows_for_editor.append({
            "record_id": rid,
            "ì¼ì‹œ(í˜„ì¬)": iso.replace("T"," ").replace("Z",""),
            "ìƒˆ_ì¼ì‹œ": new_dt_default,     # í¸ì§‘ ê°€ëŠ¥
            "êµ¬ë¶„": io,
            "CAS": cas,
            "ë¬¼ì§ˆëª…": name,
            "ìˆ˜ëŸ‰": f"{int(round(float(qty))) if qty is not None else ''}",
            "ë‹¨ìœ„": unit,
            "ê±´ë¬¼": bld,
            "í˜¸ìˆ˜": room,
            "ì‹¤í—˜ì‹¤": lab,
            "ì‚­ì œ": False,                 # ì²´í¬ë°•ìŠ¤
        })

    if not rows_for_editor:
        st.caption("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ê¸°ê°„ì„ ë„“í˜€ë³´ì„¸ìš”.")
        st.stop()

    df_edit = pd.DataFrame(rows_for_editor)
    df_edit.index = range(1, len(df_edit) + 1)
    df_edit.index.name = "No."

    edited = st.data_editor(
        df_edit,
        use_container_width=True,
        num_rows="fixed",
        column_config={
            "record_id": st.column_config.TextColumn("record_id", disabled=True, help="Airtable ë‚´ë¶€ ID"),
            "ì¼ì‹œ(í˜„ì¬)": st.column_config.TextColumn("ì¼ì‹œ(í˜„ì¬)", disabled=True),
            "ìƒˆ_ì¼ì‹œ": st.column_config.DatetimeColumn("ìƒˆ ì¼ì‹œ(ìˆ˜ì • ê°€ëŠ¥)"),
            "êµ¬ë¶„": st.column_config.TextColumn("êµ¬ë¶„", disabled=True),
            "CAS": st.column_config.TextColumn("CAS", disabled=True),
            "ë¬¼ì§ˆëª…": st.column_config.TextColumn("ë¬¼ì§ˆëª…", disabled=True),
            "ìˆ˜ëŸ‰": st.column_config.TextColumn("ìˆ˜ëŸ‰", disabled=True),
            "ë‹¨ìœ„": st.column_config.TextColumn("ë‹¨ìœ„", disabled=True),
            "ê±´ë¬¼": st.column_config.TextColumn("ê±´ë¬¼", disabled=True),
            "í˜¸ìˆ˜": st.column_config.TextColumn("í˜¸ìˆ˜", disabled=True),
            "ì‹¤í—˜ì‹¤": st.column_config.TextColumn("ì‹¤í—˜ì‹¤", disabled=True),
            "ì‚­ì œ": st.column_config.CheckboxColumn("ì‚­ì œ"),
        },
        hide_index=False,
        key="edit_logs_grid",
    )

    cola, colb = st.columns([1,3])
    apply_btn = cola.button("âœ… ì„ íƒ í•­ëª© ì ìš©")

    def to_utc_iso(dt_val: datetime) -> str:
        """ì—ë””í„°ì—ì„œ ë„˜ì–´ì˜¨ naive datetimeì„ ë¡œì»¬íƒ€ì„ìœ¼ë¡œ ê°„ì£¼ â†’ UTC Zë¡œ ë³€í™˜"""
        if dt_val is None:
            return ""
        if dt_val.tzinfo is None:
            local_tz = datetime.now().astimezone().tzinfo
            dt_val = dt_val.replace(tzinfo=local_tz)
        return dt_val.astimezone(timezone.utc).replace(microsecond=0).isoformat().replace("+00:00","Z")

    if apply_btn:
        updated, deleted, soft_deleted, errors = 0, 0, 0, 0
        for idx, row in edited.iterrows():
            rid = row.get("record_id")
            if not rid:
                continue

            # ì‚­ì œ ìš°ì„  ì²˜ë¦¬
            if bool(row.get("ì‚­ì œ", False)):
                try:
                    # íœ´ì§€í†µ ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ ì›ë³¸ ë°±ì—… í›„ ë¬¼ë¦¬ ì‚­ì œ
                    if trash_enabled():
                        orig = at_get_record(AIRTABLE_BASE_ID, tx_ref, rid)
                        ok_backup = save_to_trash(orig)
                        if not ok_backup:
                            errors += 1
                            continue
                        r = at_delete_record(AIRTABLE_BASE_ID, tx_ref, rid)
                        if r.status_code in (200, 202):
                            deleted += 1
                        else:
                            errors += 1
                    else:
                        # ì†Œí”„íŠ¸ ì‚­ì œ(í•„ë“œ 'deleted' = True)
                        r = at_update_record(AIRTABLE_BASE_ID, tx_ref, rid, {"deleted": True})
                        if r.status_code in (200, 201):
                            soft_deleted += 1
                        else:
                            errors += 1
                except Exception:
                    errors += 1
                continue

            # ì¼ì‹œ ìˆ˜ì • ì²˜ë¦¬: ë³€ê²½ ì—¬ë¶€ íŒë‹¨
            new_dt = row.get("ìƒˆ_ì¼ì‹œ")
            orig_iso = orig_time_map.get(rid, "")
            new_iso = to_utc_iso(new_dt) if isinstance(new_dt, datetime) else ""
            if new_iso and (new_iso != orig_iso):
                try:
                    r = at_update_record(AIRTABLE_BASE_ID, tx_ref, rid, {"tx_time": new_iso})
                    if r.status_code in (200, 201):
                        updated += 1
                    else:
                        errors += 1
                except Exception:
                    errors += 1

        # ê²°ê³¼ ë©”ì‹œì§€
        msg = []
        if updated: msg.append(f"ğŸ•’ ì¼ì‹œ ìˆ˜ì • {updated}ê±´")
        if deleted: msg.append(f"ğŸ—‘ï¸ ì‚­ì œ(íœ´ì§€í†µìœ¼ë¡œ ì´ë™) {deleted}ê±´")
        if soft_deleted: msg.append(f"ğŸ—‚ï¸ ì†Œí”„íŠ¸ì‚­ì œ {soft_deleted}ê±´")
        if errors:  msg.append(f"âš ï¸ ì˜¤ë¥˜ {errors}ê±´")
        if not msg: msg = ["ë³€ê²½ ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤."]
        st.success(" / ".join(msg))
        st.rerun()
# =========================
# TAB5: ğŸ—ƒï¸ íœ´ì§€í†µ(ë³µì›)
# =========================
with tab5:
    st.info("íœ´ì§€í†µì— ë³´ê´€ëœ ì‚­ì œ ì´ë ¥ì„ ë³µì›í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì„ íƒ í›„ 'ì„ íƒ í•­ëª© ë³µì›'ì„ ëˆ„ë¥´ì„¸ìš”.")

    if not trash_enabled():
        st.warning("íœ´ì§€í†µ í…Œì´ë¸”ì´ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. Secretsì— TRASH_TABLE_ID ë˜ëŠ” TRASH_TABLE_NAMEì„ ì„¤ì •í•˜ì„¸ìš”.")
        st.stop()

    if not (AIRTABLE_TOKEN and AIRTABLE_BASE_ID):
        st.error("Airtable secretsê°€ í•„ìš”í•©ë‹ˆë‹¤."); st.stop()

    tx_ref   = table_ref(AIRTABLE_TABLE_ID, AIRTABLE_TABLE_NAME)
    trash_t  = trash_ref()

    # íœ´ì§€í†µ ë ˆì½”ë“œ ë¡œë“œ
    trash_recs = get_trash_all()
    if not trash_recs:
        st.caption("íœ´ì§€í†µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
        st.stop()

    # í‘œì‹œìš© í…Œì´ë¸” êµ¬ì„±
    disp = []
    for tr in trash_recs:
        tid = tr.get("id")
        f   = tr.get("fields", {})
        orig_id   = f.get("original_record_id", "")
        deleted_at= f.get("deleted_at", "")
        raw       = f.get("raw", "")

        cas = name = qty = unit = io = bld = room = lab = ""
        tx_time = ""
        # raw JSON íŒŒì‹±
        try:
            js = json.loads(raw) if isinstance(raw, str) else raw
            fields = js.get("fields", {})
            cas   = (fields.get("CAS") or "")
            name  = fields.get("Name") or fields.get("name") or ""
            qty   = fields.get("qty")
            unit  = fields.get("unit","")
            io    = fields.get("io_type","")
            bld   = fields.get("building","")
            room  = fields.get("room","")
            lab   = fields.get("lab","")
            tx_time = fields.get("tx_time","") or js.get("createdTime","")
        except Exception:
            pass

        disp.append({
            "trash_id": tid,
            "ì‚­ì œì‹œê°": deleted_at.replace("T"," ").replace("Z",""),
            "ì›ë³¸ record_id": orig_id,
            "ì¼ì‹œ": tx_time.replace("T"," ").replace("Z",""),
            "êµ¬ë¶„": io,
            "CAS": cas,
            "ë¬¼ì§ˆëª…(íŒŒì¼ëª…)": name,
            "ìˆ˜ëŸ‰": f"{int(round(float(qty)))}" if qty not in (None,"") else "",
            "ë‹¨ìœ„": unit,
            "ê±´ë¬¼": bld, "í˜¸ìˆ˜": room, "ì‹¤í—˜ì‹¤": lab,
            "ë³µì›": False
        })

    df_trash = pd.DataFrame(disp)
    df_trash.index = range(1, len(df_trash) + 1)
    df_trash.index.name = "No."

    edited_trash = st.data_editor(
        df_trash,
        use_container_width=True,
        num_rows="fixed",
        column_config={
            "trash_id": st.column_config.TextColumn("trash_id", disabled=True),
            "ì‚­ì œì‹œê°": st.column_config.TextColumn("ì‚­ì œì‹œê°", disabled=True),
            "ì›ë³¸ record_id": st.column_config.TextColumn("ì›ë³¸ record_id", disabled=True),
            "ì¼ì‹œ": st.column_config.TextColumn("ì¼ì‹œ", disabled=True),
            "êµ¬ë¶„": st.column_config.TextColumn("êµ¬ë¶„", disabled=True),
            "CAS": st.column_config.TextColumn("CAS", disabled=True),
            "ë¬¼ì§ˆëª…(íŒŒì¼ëª…)": st.column_config.TextColumn("ë¬¼ì§ˆëª…(íŒŒì¼ëª…)", disabled=True),
            "ìˆ˜ëŸ‰": st.column_config.TextColumn("ìˆ˜ëŸ‰", disabled=True),
            "ë‹¨ìœ„": st.column_config.TextColumn("ë‹¨ìœ„", disabled=True),
            "ê±´ë¬¼": st.column_config.TextColumn("ê±´ë¬¼", disabled=True),
            "í˜¸ìˆ˜": st.column_config.TextColumn("í˜¸ìˆ˜", disabled=True),
            "ì‹¤í—˜ì‹¤": st.column_config.TextColumn("ì‹¤í—˜ì‹¤", disabled=True),
            "ë³µì›": st.column_config.CheckboxColumn("ë³µì›"),
        },
        hide_index=False,
        key="trash_editor_grid",
    )

    colx, coly = st.columns([1,3])
    restore_btn = colx.button("âœ… ì„ íƒ í•­ëª© ë³µì›")

    if restore_btn:
        restored = removed = errors = 0
        # ì›ë³¸ í…Œì´ë¸” í‚¤
        for _, row in edited_trash.iterrows():
            if not bool(row.get("ë³µì›", False)):
                continue
            tid = row.get("trash_id")
            # íœ´ì§€í†µ ë ˆì½”ë“œ ìƒì„¸ë¥¼ ë‹¤ì‹œ ë¶ˆëŸ¬ì„œ raw ì´ìš©
            try:
                rec = at_get_record(AIRTABLE_BASE_ID, trash_t, tid)
                if not rec:
                    errors += 1
                    continue
                f = rec.get("fields", {})
                raw = f.get("raw", "")
                js  = json.loads(raw) if isinstance(raw, str) else raw
                fields = (js or {}).get("fields", {})
                if not isinstance(fields, dict) or not fields:
                    errors += 1
                    continue

                # ì•ˆì „í•˜ê²Œ ë³µì›: ì†Œí”„íŠ¸ì‚­ì œ í”ì  ì œê±°
                fields.pop("deleted", None)
                # Airtableì— ë‹¤ì‹œ ìƒì„±
                r = at_create_record(AIRTABLE_BASE_ID, tx_ref, fields)
                if r.status_code in (200, 201):
                    restored += 1
                    # íœ´ì§€í†µì—ì„œ ì‚­ì œ
                    d = at_delete_record(AIRTABLE_BASE_ID, trash_t, tid)
                    if d.status_code in (200, 202):
                        removed += 1
                else:
                    errors += 1
            except Exception:
                errors += 1

        msg = []
        if restored: msg.append(f"â™»ï¸ ë³µì› {restored}ê±´")
        if removed:  msg.append(f"ğŸ§¹ íœ´ì§€í†µ ì •ë¦¬ {removed}ê±´")
        if errors:   msg.append(f"âš ï¸ ì˜¤ë¥˜ {errors}ê±´")
        if not msg:  msg = ["ë³€ê²½ ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤."]
        st.success(" / ".join(msg))
        st.rerun()
